{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from src_nowcasting import image_preprocessing, sequence_img_generator, get_models\n",
    "from datetime import datetime\n",
    "from pvlib import location, solarposition\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "\n",
    "- add explaination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_INPUT_FOLDER = r'D:\\001_Nowcasting\\IR_images_nowcasting'\n",
    "# PATH_OUTPUT_FOLDER = r'D:\\001_Nowcasting\\IR_images_postprocess'\n",
    "\n",
    "# pre_processor = image_preprocessing.PreProcessImage()\n",
    "\n",
    "# # go through all the days in the folder\n",
    "# for day in tqdm(os.listdir(PATH_INPUT_FOLDER)):    \n",
    "\n",
    "#    # go through all the images in the day\n",
    "#     files = os.listdir(os.path.join(PATH_INPUT_FOLDER, day))\n",
    "\n",
    "#     for f in files:\n",
    "\n",
    "#         # Load image\n",
    "#         in_path = os.path.join(PATH_INPUT_FOLDER, day, f)\n",
    "#         image =  cv2.imread(in_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "#         # Transform image\n",
    "#         new_image = pre_processor.transform_image(image)\n",
    "\n",
    "#         # Save image\n",
    "#         folder_path = os.path.join(PATH_OUTPUT_FOLDER, day)\n",
    "#         # Check if exists and if not create folder\n",
    "#         if not os.path.exists(folder_path): os.mkdir(folder_path)\n",
    "#         out_path = os.path.join(folder_path, f.split('.')[0]+'.jpg')\n",
    "\n",
    "#         cv2.imwrite(out_path, new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = sequence_img_generator.generate_dataframe(r'C:\\Users\\Admin\\Code\\maciej-solar-nowcasting\\dataset\\sensors', 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, metrics\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow as tf\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/Admin/Code/maciej-solar-nowcasting/nowcasting/mlruns/4', creation_time=1696335798033, experiment_id='4', last_update_time=1696335798033, lifecycle_stage='active', name='sCNN_best_model_tests', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"sCNN_best_model_tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = 'scnn'                                         # model_type chosen for the training.\n",
    "FORECAST_HORIZON = 30                                       # time horizon.\n",
    "NO_IMAGES = 3\n",
    "EPSILON = 1e-3\n",
    "\n",
    "# Image parameters\n",
    "img_size = [128, 128]                                       # image size.\n",
    "img_channels = 1                                            # image channels.\n",
    "ELEVATION_THRESHOLD = 20\n",
    "\n",
    "train_batchsize = 32                                        # batch size for train.\n",
    "test_batchsize = 1                                          # batch size for test.\n",
    "epochs = 100                                                # maximum number of epochs.\n",
    "TRAIN_SIZE = 0.8\n",
    "I = 0\n",
    "\n",
    "# Paths\n",
    "# path = constants.REGR_SEQ_DATASET_DIR                                                  \n",
    "WEIGHT_PATH = r'.\\model\\weights'          # path to the weight.\n",
    "LOG_PATH = None                     # path to save the CSV file.\n",
    "CHECKPOINT_PATH = r'.\\model\\checkpoints'\n",
    "IMAGE_PATH = r'C:\\Users\\Admin\\Code\\maciej-solar-nowcasting\\dataset\\IR_images_postprocess'\n",
    "\n",
    "# root_logdir = os.path.join(os.curdir, \"run_regression/my_logs\")\n",
    "\n",
    "params1 = {'batch_size': train_batchsize,\n",
    "           'dim': (img_size[0], img_size[1], 1 * NO_IMAGES),\n",
    "           'channel_IMG': img_channels,\n",
    "           'shuffle': False,\n",
    "           'iftest': False}\n",
    "\n",
    "params2 = {'batch_size': train_batchsize,\n",
    "           'dim': (img_size[0], img_size[1], 1 * NO_IMAGES),\n",
    "           'channel_IMG': img_channels,\n",
    "           'iftest': False}\n",
    "\n",
    "params3 = {'batch_size': test_batchsize,\n",
    "           'dim': (img_size[0], img_size[1], 1 * NO_IMAGES),\n",
    "           'channel_IMG': img_channels,\n",
    "           'shuffle': False,\n",
    "           'iftest': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "   'SCNN': get_models.SCNN(input_shape=[img_size[0], img_size[1], NO_IMAGES]),\n",
    "   'SCNN_small_v2': get_models.SCNN_small_2(input_shape=[img_size[0], img_size[1], NO_IMAGES]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_parquet(r'..\\dataset\\df_data_15.parquet.gzip')\n",
    "\n",
    "# Define the Target column\n",
    "df_data['Target'] = df_data.Target_CSI\n",
    "\n",
    "# Remove the data with low elevation\n",
    "df_data_reduced = df_data[df_data.elevation > ELEVATION_THRESHOLD]\n",
    "\n",
    "\n",
    "df_train_full, df_test = model_selection.train_test_split(df_data_reduced, train_size=TRAIN_SIZE, shuffle=False)\n",
    "df_train, df_val = model_selection.train_test_split(df_train_full, train_size=TRAIN_SIZE, shuffle=False)\n",
    "\n",
    "train_generator = sequence_img_generator.DataGeneratorGHI_SCNN(df_train, IMAGE_PATH, **params1)\n",
    "\n",
    "val_generator = sequence_img_generator.DataGeneratorGHI_SCNN(df_val, IMAGE_PATH, **params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases\n",
    "\n",
    "# Sunny day test - 19/08/2023. 23/08/2023\n",
    "# Partially cloudy day test - 26/08/2023, 29/08/2023\n",
    "# Mostly cloudy / rainy day test - 27/08/2023\n",
    "\n",
    "df_test_1 = df_test[df_test.date.dt.date == datetime(2023, 8, 19).date()].copy() # Sunny day\n",
    "df_test_2 = df_test[df_test.date.dt.date == datetime(2023, 8, 23).date()].copy() # Sunny day\n",
    "df_test_3 = df_test[df_test.date.dt.date == datetime(2023, 8, 26).date()].copy() # Partially cloudy day\n",
    "df_test_4 = df_test[df_test.date.dt.date == datetime(2023, 8, 27).date()].copy() # Mostly cloudy / rainy day\n",
    "df_test_5 = df_test[df_test.date.dt.date == datetime(2023, 8, 29).date()].copy() # Partially cloudy day\n",
    "\n",
    "test_cases = [df_test_1, df_test_2, df_test_3, df_test_4, df_test_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.1294 - root_mean_squared_error: 0.3597\n",
      "Epoch 1: val_loss improved from inf to 0.05851, saving model to .\\model\\checkpoints\\training_id_SCNN_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 125s 148ms/step - loss: 0.1294 - root_mean_squared_error: 0.3597 - val_loss: 0.0585 - val_root_mean_squared_error: 0.2419\n",
      "Epoch 2/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0829 - root_mean_squared_error: 0.2879\n",
      "Epoch 2: val_loss improved from 0.05851 to 0.03428, saving model to .\\model\\checkpoints\\training_id_SCNN_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 116s 150ms/step - loss: 0.0829 - root_mean_squared_error: 0.2879 - val_loss: 0.0343 - val_root_mean_squared_error: 0.1851\n",
      "Epoch 3/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0780 - root_mean_squared_error: 0.2793\n",
      "Epoch 3: val_loss improved from 0.03428 to 0.02937, saving model to .\\model\\checkpoints\\training_id_SCNN_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 116s 150ms/step - loss: 0.0780 - root_mean_squared_error: 0.2793 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1714\n",
      "Epoch 4/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0863 - root_mean_squared_error: 0.2938\n",
      "Epoch 4: val_loss did not improve from 0.02937\n",
      "776/776 [==============================] - 116s 149ms/step - loss: 0.0863 - root_mean_squared_error: 0.2938 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1721\n",
      "Epoch 5/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0817 - root_mean_squared_error: 0.2858\n",
      "Epoch 5: val_loss did not improve from 0.02937\n",
      "776/776 [==============================] - 116s 149ms/step - loss: 0.0817 - root_mean_squared_error: 0.2858 - val_loss: 0.0322 - val_root_mean_squared_error: 0.1794\n",
      "Epoch 6/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0784 - root_mean_squared_error: 0.2801\n",
      "Epoch 6: val_loss did not improve from 0.02937\n",
      "776/776 [==============================] - 116s 150ms/step - loss: 0.0784 - root_mean_squared_error: 0.2801 - val_loss: 0.0404 - val_root_mean_squared_error: 0.2010\n",
      "Epoch 7/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0724 - root_mean_squared_error: 0.2690\n",
      "Epoch 7: val_loss did not improve from 0.02937\n",
      "776/776 [==============================] - 116s 150ms/step - loss: 0.0724 - root_mean_squared_error: 0.2690 - val_loss: 0.0364 - val_root_mean_squared_error: 0.1907\n",
      "Epoch 8/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0775 - root_mean_squared_error: 0.2784\n",
      "Epoch 8: val_loss did not improve from 0.02937\n",
      "776/776 [==============================] - 115s 148ms/step - loss: 0.0775 - root_mean_squared_error: 0.2784 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1748\n",
      "Epoch 9/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0703 - root_mean_squared_error: 0.2652\n",
      "Epoch 9: val_loss improved from 0.02937 to 0.02857, saving model to .\\model\\checkpoints\\training_id_SCNN_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 112s 145ms/step - loss: 0.0703 - root_mean_squared_error: 0.2652 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1690\n",
      "Epoch 10/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0698 - root_mean_squared_error: 0.2643\n",
      "Epoch 10: val_loss did not improve from 0.02857\n",
      "776/776 [==============================] - 112s 144ms/step - loss: 0.0698 - root_mean_squared_error: 0.2643 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1691\n",
      "Epoch 11/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0687 - root_mean_squared_error: 0.2621\n",
      "Epoch 11: val_loss did not improve from 0.02857\n",
      "776/776 [==============================] - 112s 144ms/step - loss: 0.0687 - root_mean_squared_error: 0.2621 - val_loss: 0.0599 - val_root_mean_squared_error: 0.2447\n",
      "Epoch 12/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0668 - root_mean_squared_error: 0.2584\n",
      "Epoch 12: val_loss improved from 0.02857 to 0.02740, saving model to .\\model\\checkpoints\\training_id_SCNN_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 112s 144ms/step - loss: 0.0668 - root_mean_squared_error: 0.2584 - val_loss: 0.0274 - val_root_mean_squared_error: 0.1655\n",
      "Epoch 13/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0649 - root_mean_squared_error: 0.2548\n",
      "Epoch 13: val_loss improved from 0.02740 to 0.02667, saving model to .\\model\\checkpoints\\training_id_SCNN_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 112s 144ms/step - loss: 0.0649 - root_mean_squared_error: 0.2548 - val_loss: 0.0267 - val_root_mean_squared_error: 0.1633\n",
      "Epoch 14/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0622 - root_mean_squared_error: 0.2495\n",
      "Epoch 14: val_loss did not improve from 0.02667\n",
      "776/776 [==============================] - 112s 144ms/step - loss: 0.0622 - root_mean_squared_error: 0.2495 - val_loss: 0.0288 - val_root_mean_squared_error: 0.1698\n",
      "Epoch 15/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0620 - root_mean_squared_error: 0.2491\n",
      "Epoch 15: val_loss did not improve from 0.02667\n",
      "776/776 [==============================] - 112s 144ms/step - loss: 0.0620 - root_mean_squared_error: 0.2491 - val_loss: 0.0272 - val_root_mean_squared_error: 0.1648\n",
      "Epoch 16/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0589 - root_mean_squared_error: 0.2428\n",
      "Epoch 16: val_loss improved from 0.02667 to 0.02580, saving model to .\\model\\checkpoints\\training_id_SCNN_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 112s 144ms/step - loss: 0.0589 - root_mean_squared_error: 0.2428 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1606\n",
      "Epoch 17/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0585 - root_mean_squared_error: 0.2419\n",
      "Epoch 17: val_loss did not improve from 0.02580\n",
      "776/776 [==============================] - 111s 144ms/step - loss: 0.0585 - root_mean_squared_error: 0.2419 - val_loss: 0.0259 - val_root_mean_squared_error: 0.1608\n",
      "Epoch 18/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0590 - root_mean_squared_error: 0.2429\n",
      "Epoch 18: val_loss improved from 0.02580 to 0.02532, saving model to .\\model\\checkpoints\\training_id_SCNN_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 112s 144ms/step - loss: 0.0590 - root_mean_squared_error: 0.2429 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1591\n",
      "Epoch 19/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0575 - root_mean_squared_error: 0.2399\n",
      "Epoch 19: val_loss improved from 0.02532 to 0.02469, saving model to .\\model\\checkpoints\\training_id_SCNN_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 112s 144ms/step - loss: 0.0575 - root_mean_squared_error: 0.2399 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1571\n",
      "Epoch 20/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0573 - root_mean_squared_error: 0.2393\n",
      "Epoch 20: val_loss did not improve from 0.02469\n",
      "776/776 [==============================] - 111s 143ms/step - loss: 0.0573 - root_mean_squared_error: 0.2393 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1596\n",
      "Epoch 21/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0578 - root_mean_squared_error: 0.2405\n",
      "Epoch 21: val_loss did not improve from 0.02469\n",
      "776/776 [==============================] - 111s 143ms/step - loss: 0.0578 - root_mean_squared_error: 0.2405 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1619\n",
      "Epoch 22/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0563 - root_mean_squared_error: 0.2372\n",
      "Epoch 22: val_loss did not improve from 0.02469\n",
      "776/776 [==============================] - 111s 143ms/step - loss: 0.0563 - root_mean_squared_error: 0.2372 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1593\n",
      "Epoch 23/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0573 - root_mean_squared_error: 0.2395\n",
      "Epoch 23: val_loss did not improve from 0.02469\n",
      "776/776 [==============================] - 111s 144ms/step - loss: 0.0573 - root_mean_squared_error: 0.2395 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1625\n",
      "Epoch 24/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0563 - root_mean_squared_error: 0.2374\n",
      "Epoch 24: val_loss did not improve from 0.02469\n",
      "776/776 [==============================] - 111s 143ms/step - loss: 0.0563 - root_mean_squared_error: 0.2374 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1682\n",
      "Epoch 25/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0555 - root_mean_squared_error: 0.2356\n",
      "Epoch 25: val_loss did not improve from 0.02469\n",
      "776/776 [==============================] - 111s 143ms/step - loss: 0.0555 - root_mean_squared_error: 0.2356 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1653\n",
      "Epoch 26/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0528 - root_mean_squared_error: 0.2297\n",
      "Epoch 26: val_loss improved from 0.02469 to 0.02438, saving model to .\\model\\checkpoints\\training_id_SCNN_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 112s 144ms/step - loss: 0.0528 - root_mean_squared_error: 0.2297 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1561\n",
      "Epoch 27/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0528 - root_mean_squared_error: 0.2299\n",
      "Epoch 27: val_loss did not improve from 0.02438\n",
      "776/776 [==============================] - 111s 144ms/step - loss: 0.0528 - root_mean_squared_error: 0.2299 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1699\n",
      "Epoch 28/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0522 - root_mean_squared_error: 0.2285\n",
      "Epoch 28: val_loss did not improve from 0.02438\n",
      "776/776 [==============================] - 111s 143ms/step - loss: 0.0522 - root_mean_squared_error: 0.2285 - val_loss: 0.0279 - val_root_mean_squared_error: 0.1670\n",
      "Epoch 29/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0522 - root_mean_squared_error: 0.2284\n",
      "Epoch 29: val_loss did not improve from 0.02438\n",
      "776/776 [==============================] - 111s 143ms/step - loss: 0.0522 - root_mean_squared_error: 0.2284 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1591\n",
      "Epoch 30/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0510 - root_mean_squared_error: 0.2258\n",
      "Epoch 30: val_loss did not improve from 0.02438\n",
      "776/776 [==============================] - 111s 143ms/step - loss: 0.0510 - root_mean_squared_error: 0.2258 - val_loss: 0.0279 - val_root_mean_squared_error: 0.1671\n",
      "Epoch 31/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0505 - root_mean_squared_error: 0.2248\n",
      "Epoch 31: val_loss did not improve from 0.02438\n",
      "776/776 [==============================] - 111s 143ms/step - loss: 0.0505 - root_mean_squared_error: 0.2248 - val_loss: 0.0274 - val_root_mean_squared_error: 0.1656\n",
      "Epoch 32/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0506 - root_mean_squared_error: 0.2249\n",
      "Epoch 32: val_loss did not improve from 0.02438\n",
      "776/776 [==============================] - 111s 143ms/step - loss: 0.0506 - root_mean_squared_error: 0.2249 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1574\n",
      "Epoch 33/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0510 - root_mean_squared_error: 0.2259\n",
      "Epoch 33: val_loss did not improve from 0.02438\n",
      "776/776 [==============================] - 111s 144ms/step - loss: 0.0510 - root_mean_squared_error: 0.2259 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1595\n",
      "Epoch 34/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0486 - root_mean_squared_error: 0.2204\n",
      "Epoch 34: val_loss improved from 0.02438 to 0.02319, saving model to .\\model\\checkpoints\\training_id_SCNN_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 112s 144ms/step - loss: 0.0486 - root_mean_squared_error: 0.2204 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1523\n",
      "Epoch 35/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0485 - root_mean_squared_error: 0.2201\n",
      "Epoch 35: val_loss did not improve from 0.02319\n",
      "776/776 [==============================] - 225s 290ms/step - loss: 0.0485 - root_mean_squared_error: 0.2201 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1588\n",
      "Epoch 36/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0484 - root_mean_squared_error: 0.2200\n",
      "Epoch 36: val_loss did not improve from 0.02319\n",
      "776/776 [==============================] - 137s 176ms/step - loss: 0.0484 - root_mean_squared_error: 0.2200 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1573\n",
      "Epoch 37/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0474 - root_mean_squared_error: 0.2177\n",
      "Epoch 37: val_loss did not improve from 0.02319\n",
      "776/776 [==============================] - 111s 144ms/step - loss: 0.0474 - root_mean_squared_error: 0.2177 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1575\n",
      "Epoch 38/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0469 - root_mean_squared_error: 0.2167\n",
      "Epoch 38: val_loss did not improve from 0.02319\n",
      "776/776 [==============================] - 112s 144ms/step - loss: 0.0469 - root_mean_squared_error: 0.2167 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1612\n",
      "Epoch 39/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0461 - root_mean_squared_error: 0.2148\n",
      "Epoch 39: val_loss did not improve from 0.02319\n",
      "776/776 [==============================] - 220s 284ms/step - loss: 0.0461 - root_mean_squared_error: 0.2148 - val_loss: 0.0270 - val_root_mean_squared_error: 0.1644\n",
      "Epoch 40/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0461 - root_mean_squared_error: 0.2146\n",
      "Epoch 40: val_loss improved from 0.02319 to 0.02298, saving model to .\\model\\checkpoints\\training_id_SCNN_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 137s 176ms/step - loss: 0.0461 - root_mean_squared_error: 0.2146 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1516\n",
      "Epoch 41/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0454 - root_mean_squared_error: 0.2131\n",
      "Epoch 41: val_loss did not improve from 0.02298\n",
      "776/776 [==============================] - 111s 143ms/step - loss: 0.0454 - root_mean_squared_error: 0.2131 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1657\n",
      "Epoch 42/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0448 - root_mean_squared_error: 0.2116\n",
      "Epoch 42: val_loss did not improve from 0.02298\n",
      "776/776 [==============================] - 111s 144ms/step - loss: 0.0448 - root_mean_squared_error: 0.2116 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1591\n",
      "Epoch 43/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0444 - root_mean_squared_error: 0.2107\n",
      "Epoch 43: val_loss did not improve from 0.02298\n",
      "776/776 [==============================] - 111s 144ms/step - loss: 0.0444 - root_mean_squared_error: 0.2107 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1591\n",
      "Epoch 44/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0442 - root_mean_squared_error: 0.2103\n",
      "Epoch 44: val_loss did not improve from 0.02298\n",
      "776/776 [==============================] - 111s 143ms/step - loss: 0.0442 - root_mean_squared_error: 0.2103 - val_loss: 0.0277 - val_root_mean_squared_error: 0.1665\n",
      "Epoch 45/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0441 - root_mean_squared_error: 0.2100\n",
      "Epoch 45: val_loss did not improve from 0.02298\n",
      "776/776 [==============================] - 111s 144ms/step - loss: 0.0441 - root_mean_squared_error: 0.2100 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1618\n",
      "Epoch 46/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0432 - root_mean_squared_error: 0.2079\n",
      "Epoch 46: val_loss did not improve from 0.02298\n",
      "776/776 [==============================] - 111s 144ms/step - loss: 0.0432 - root_mean_squared_error: 0.2079 - val_loss: 0.0259 - val_root_mean_squared_error: 0.1608\n",
      "Epoch 47/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0424 - root_mean_squared_error: 0.2058\n",
      "Epoch 47: val_loss did not improve from 0.02298\n",
      "776/776 [==============================] - 111s 143ms/step - loss: 0.0424 - root_mean_squared_error: 0.2058 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1784\n",
      "Epoch 48/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0417 - root_mean_squared_error: 0.2043\n",
      "Epoch 48: val_loss did not improve from 0.02298\n",
      "776/776 [==============================] - 111s 143ms/step - loss: 0.0417 - root_mean_squared_error: 0.2043 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1596\n",
      "Epoch 49/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0410 - root_mean_squared_error: 0.2025\n",
      "Epoch 49: val_loss did not improve from 0.02298\n",
      "776/776 [==============================] - 111s 143ms/step - loss: 0.0410 - root_mean_squared_error: 0.2025 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1721\n",
      "Epoch 50/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0396 - root_mean_squared_error: 0.1991\n",
      "Epoch 50: val_loss did not improve from 0.02298\n",
      "776/776 [==============================] - 111s 143ms/step - loss: 0.0396 - root_mean_squared_error: 0.1991 - val_loss: 0.0252 - val_root_mean_squared_error: 0.1588\n",
      "595/595 [==============================] - 6s 9ms/step\n",
      "Test case: 2023-08-19\n",
      "model_params: 16812353\n",
      "mae_test: 1501.3091228262558\n",
      "mae_pers 1697.8547700708627\n",
      "FS: 0.11576116562455085\n",
      "584/584 [==============================] - 5s 9ms/step\n",
      "Test case: 2023-08-23\n",
      "model_params: 16812353\n",
      "mae_test: 1305.0223210932681\n",
      "mae_pers 1213.133013807506\n",
      "FS: -0.07574545102631491\n",
      "575/575 [==============================] - 5s 9ms/step\n",
      "Test case: 2023-08-26\n",
      "model_params: 16812353\n",
      "mae_test: 34015.1222101386\n",
      "mae_pers 24207.85466466567\n",
      "FS: -0.4051274960679536\n",
      "573/573 [==============================] - 5s 9ms/step\n",
      "Test case: 2023-08-27\n",
      "model_params: 16812353\n",
      "mae_test: 63316.389739621685\n",
      "mae_pers 11006.400416968443\n",
      "FS: -4.752688194226291\n",
      "567/567 [==============================] - 5s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/10/05 13:50:04 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case: 2023-08-29\n",
      "model_params: 16812353\n",
      "mae_test: 35032.94174716967\n",
      "mae_pers 27290.129370086215\n",
      "FS: -0.28372208398435284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpoxvnbhm2\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpoxvnbhm2\\model\\data\\model\\assets\n",
      "c:\\Users\\Admin\\.conda\\envs\\ms\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.1077 - root_mean_squared_error: 0.3282\n",
      "Epoch 1: val_loss improved from inf to 0.03236, saving model to .\\model\\checkpoints\\training_id_SCNN_small_v2_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 114s 142ms/step - loss: 0.1077 - root_mean_squared_error: 0.3282 - val_loss: 0.0324 - val_root_mean_squared_error: 0.1799\n",
      "Epoch 2/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0849 - root_mean_squared_error: 0.2914\n",
      "Epoch 2: val_loss did not improve from 0.03236\n",
      "776/776 [==============================] - 104s 135ms/step - loss: 0.0849 - root_mean_squared_error: 0.2914 - val_loss: 0.0532 - val_root_mean_squared_error: 0.2307\n",
      "Epoch 3/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0773 - root_mean_squared_error: 0.2780\n",
      "Epoch 3: val_loss did not improve from 0.03236\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0773 - root_mean_squared_error: 0.2780 - val_loss: 0.0503 - val_root_mean_squared_error: 0.2243\n",
      "Epoch 4/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0777 - root_mean_squared_error: 0.2787\n",
      "Epoch 4: val_loss improved from 0.03236 to 0.03061, saving model to .\\model\\checkpoints\\training_id_SCNN_small_v2_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0777 - root_mean_squared_error: 0.2787 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1750\n",
      "Epoch 5/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0722 - root_mean_squared_error: 0.2687\n",
      "Epoch 5: val_loss did not improve from 0.03061\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0722 - root_mean_squared_error: 0.2687 - val_loss: 0.0316 - val_root_mean_squared_error: 0.1777\n",
      "Epoch 6/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0646 - root_mean_squared_error: 0.2542\n",
      "Epoch 6: val_loss improved from 0.03061 to 0.02624, saving model to .\\model\\checkpoints\\training_id_SCNN_small_v2_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0646 - root_mean_squared_error: 0.2542 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1620\n",
      "Epoch 7/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0720 - root_mean_squared_error: 0.2684\n",
      "Epoch 7: val_loss improved from 0.02624 to 0.02491, saving model to .\\model\\checkpoints\\training_id_SCNN_small_v2_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0720 - root_mean_squared_error: 0.2684 - val_loss: 0.0249 - val_root_mean_squared_error: 0.1578\n",
      "Epoch 8/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0605 - root_mean_squared_error: 0.2460\n",
      "Epoch 8: val_loss improved from 0.02491 to 0.02343, saving model to .\\model\\checkpoints\\training_id_SCNN_small_v2_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0605 - root_mean_squared_error: 0.2460 - val_loss: 0.0234 - val_root_mean_squared_error: 0.1531\n",
      "Epoch 9/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0583 - root_mean_squared_error: 0.2415\n",
      "Epoch 9: val_loss did not improve from 0.02343\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0583 - root_mean_squared_error: 0.2415 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1694\n",
      "Epoch 10/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0572 - root_mean_squared_error: 0.2391\n",
      "Epoch 10: val_loss did not improve from 0.02343\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0572 - root_mean_squared_error: 0.2391 - val_loss: 0.0430 - val_root_mean_squared_error: 0.2074\n",
      "Epoch 11/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0569 - root_mean_squared_error: 0.2385\n",
      "Epoch 11: val_loss did not improve from 0.02343\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0569 - root_mean_squared_error: 0.2385 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1601\n",
      "Epoch 12/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0554 - root_mean_squared_error: 0.2355\n",
      "Epoch 12: val_loss improved from 0.02343 to 0.02266, saving model to .\\model\\checkpoints\\training_id_SCNN_small_v2_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0554 - root_mean_squared_error: 0.2355 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1505\n",
      "Epoch 13/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0559 - root_mean_squared_error: 0.2365\n",
      "Epoch 13: val_loss improved from 0.02266 to 0.02189, saving model to .\\model\\checkpoints\\training_id_SCNN_small_v2_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0559 - root_mean_squared_error: 0.2365 - val_loss: 0.0219 - val_root_mean_squared_error: 0.1480\n",
      "Epoch 14/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0535 - root_mean_squared_error: 0.2312\n",
      "Epoch 14: val_loss did not improve from 0.02189\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0535 - root_mean_squared_error: 0.2312 - val_loss: 0.0363 - val_root_mean_squared_error: 0.1904\n",
      "Epoch 15/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0546 - root_mean_squared_error: 0.2336\n",
      "Epoch 15: val_loss did not improve from 0.02189\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0546 - root_mean_squared_error: 0.2336 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1593\n",
      "Epoch 16/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0539 - root_mean_squared_error: 0.2321\n",
      "Epoch 16: val_loss did not improve from 0.02189\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0539 - root_mean_squared_error: 0.2321 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1539\n",
      "Epoch 17/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0525 - root_mean_squared_error: 0.2292\n",
      "Epoch 17: val_loss did not improve from 0.02189\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0525 - root_mean_squared_error: 0.2292 - val_loss: 0.0335 - val_root_mean_squared_error: 0.1830\n",
      "Epoch 18/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0534 - root_mean_squared_error: 0.2311\n",
      "Epoch 18: val_loss did not improve from 0.02189\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0534 - root_mean_squared_error: 0.2311 - val_loss: 0.0239 - val_root_mean_squared_error: 0.1547\n",
      "Epoch 19/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0512 - root_mean_squared_error: 0.2263\n",
      "Epoch 19: val_loss did not improve from 0.02189\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0512 - root_mean_squared_error: 0.2263 - val_loss: 0.0238 - val_root_mean_squared_error: 0.1543\n",
      "Epoch 20/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0504 - root_mean_squared_error: 0.2245\n",
      "Epoch 20: val_loss did not improve from 0.02189\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0504 - root_mean_squared_error: 0.2245 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1725\n",
      "Epoch 21/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0504 - root_mean_squared_error: 0.2245\n",
      "Epoch 21: val_loss did not improve from 0.02189\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0504 - root_mean_squared_error: 0.2245 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1700\n",
      "Epoch 22/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0509 - root_mean_squared_error: 0.2257\n",
      "Epoch 22: val_loss did not improve from 0.02189\n",
      "776/776 [==============================] - 104s 133ms/step - loss: 0.0509 - root_mean_squared_error: 0.2257 - val_loss: 0.0274 - val_root_mean_squared_error: 0.1655\n",
      "Epoch 23/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0494 - root_mean_squared_error: 0.2224\n",
      "Epoch 23: val_loss improved from 0.02189 to 0.02064, saving model to .\\model\\checkpoints\\training_id_SCNN_small_v2_scaled_15_0.0003_mean_squared_error.h5\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0494 - root_mean_squared_error: 0.2224 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1437\n",
      "Epoch 24/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0496 - root_mean_squared_error: 0.2228\n",
      "Epoch 24: val_loss did not improve from 0.02064\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0496 - root_mean_squared_error: 0.2228 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1440\n",
      "Epoch 25/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0491 - root_mean_squared_error: 0.2215\n",
      "Epoch 25: val_loss did not improve from 0.02064\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0491 - root_mean_squared_error: 0.2215 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1552\n",
      "Epoch 26/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0477 - root_mean_squared_error: 0.2183\n",
      "Epoch 26: val_loss did not improve from 0.02064\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0477 - root_mean_squared_error: 0.2183 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1562\n",
      "Epoch 27/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0481 - root_mean_squared_error: 0.2194\n",
      "Epoch 27: val_loss did not improve from 0.02064\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0481 - root_mean_squared_error: 0.2194 - val_loss: 0.0223 - val_root_mean_squared_error: 0.1494\n",
      "Epoch 28/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0470 - root_mean_squared_error: 0.2169\n",
      "Epoch 28: val_loss did not improve from 0.02064\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0470 - root_mean_squared_error: 0.2169 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1457\n",
      "Epoch 29/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0467 - root_mean_squared_error: 0.2162\n",
      "Epoch 29: val_loss did not improve from 0.02064\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0467 - root_mean_squared_error: 0.2162 - val_loss: 0.0355 - val_root_mean_squared_error: 0.1885\n",
      "Epoch 30/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0459 - root_mean_squared_error: 0.2141\n",
      "Epoch 30: val_loss did not improve from 0.02064\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0459 - root_mean_squared_error: 0.2141 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1557\n",
      "Epoch 31/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0444 - root_mean_squared_error: 0.2107\n",
      "Epoch 31: val_loss did not improve from 0.02064\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0444 - root_mean_squared_error: 0.2107 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1506\n",
      "Epoch 32/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0437 - root_mean_squared_error: 0.2090\n",
      "Epoch 32: val_loss did not improve from 0.02064\n",
      "776/776 [==============================] - 104s 133ms/step - loss: 0.0437 - root_mean_squared_error: 0.2090 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1460\n",
      "Epoch 33/100\n",
      "776/776 [==============================] - ETA: 0s - loss: 0.0425 - root_mean_squared_error: 0.2061\n",
      "Epoch 33: val_loss did not improve from 0.02064\n",
      "776/776 [==============================] - 104s 134ms/step - loss: 0.0425 - root_mean_squared_error: 0.2061 - val_loss: 0.0227 - val_root_mean_squared_error: 0.1507\n",
      "595/595 [==============================] - 2s 3ms/step\n",
      "Test case: 2023-08-19\n",
      "model_params: 16024385\n",
      "mae_test: 980.2850537084861\n",
      "mae_pers 1697.8547700708627\n",
      "FS: 0.42263315391364586\n",
      "584/584 [==============================] - 2s 3ms/step\n",
      "Test case: 2023-08-23\n",
      "model_params: 16024385\n",
      "mae_test: 593.7626834044784\n",
      "mae_pers 1213.133013807506\n",
      "FS: 0.5105543442916362\n",
      "575/575 [==============================] - 2s 3ms/step\n",
      "Test case: 2023-08-26\n",
      "model_params: 16024385\n",
      "mae_test: 30325.406442709973\n",
      "mae_pers 24207.85466466567\n",
      "FS: -0.25270937316777675\n",
      "573/573 [==============================] - 2s 3ms/step\n",
      "Test case: 2023-08-27\n",
      "model_params: 16024385\n",
      "mae_test: 39282.28556552603\n",
      "mae_pers 11006.400416968443\n",
      "FS: -2.569040201823384\n",
      "567/567 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/10/05 14:47:49 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case: 2023-08-29\n",
      "model_params: 16024385\n",
      "mae_test: 25783.59552584394\n",
      "mae_pers 27290.129370086215\n",
      "FS: 0.05520434966840604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpx50lq2h7\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpx50lq2h7\\model\\data\\model\\assets\n"
     ]
    }
   ],
   "source": [
    "mlflow.tensorflow.autolog(disable=True)\n",
    "\n",
    "# Parameters\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "\n",
    "LEARNING_RATE_START = 0.0003\n",
    "LOSS = 'mean_squared_error'\n",
    "\n",
    "def exponential_decay_fn(epoch, learning_rate=LEARNING_RATE_START):\n",
    "    return learning_rate * 0.1**(epoch / 20)\n",
    "\n",
    "RUN_ID = 1\n",
    "\n",
    "for m in models:\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    with mlflow.start_run(run_name=f'run_{RUN_ID:03d}_{m}_scaled_15, lr: 0.0003, loss: {LOSS}'):\n",
    "        params = {\n",
    "            'forecast_horizon': FORECAST_HORIZON,\n",
    "            'elevation_threshold': ELEVATION_THRESHOLD,\n",
    "            'model_type': MODEL_TYPE,\n",
    "            'learning_rate': '1C',\n",
    "            'beta_1': BETA_1,\n",
    "            'beta_2': BETA_2,\n",
    "            'loss': 'mean_squared_error',\n",
    "                \n",
    "        }\n",
    "            \n",
    "        callbacks_list = []\n",
    "        model = models[m]\n",
    "        \n",
    "        # Logging\n",
    "        if LOG_PATH: \n",
    "            callbacks_list.append(callbacks.CSVLogger(os.path.join(LOG_PATH, f'training_id_{m}_{LEARNING_RATE_START}.csv')))\n",
    "        # Checkpointing\n",
    "        if CHECKPOINT_PATH:\n",
    "            callbacks_list.append(callbacks.ModelCheckpoint(\n",
    "                filepath=os.path.join(CHECKPOINT_PATH, f'training_id_{m}_scaled_15_0.0003_{LOSS}.h5'),\n",
    "                verbose = 1,\n",
    "                save_best_only = True,\n",
    "                ))\n",
    "\n",
    "        # Early stopping\n",
    "        callbacks_list.append(callbacks.EarlyStopping(monitor='val_loss', patience=10))\n",
    "        # Learing rate reduction scheduler\n",
    "        # callbacks_list.append(get_models.OneCycleScheduler(math.ceil(len(df_train) / train_batchsize) * epochs, max_rate = 0.0005))\n",
    "        # callbacks_list.append(tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn))\n",
    "                    \n",
    "        optimizer = optimizers.Adam(\n",
    "            learning_rate=LEARNING_RATE_START, \n",
    "            beta_1=0.9, \n",
    "            beta_2=0.999, \n",
    "            amsgrad=False\n",
    "            )\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer, \n",
    "            loss=LOSS,\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "            )\n",
    "\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            #steps_per_epoch=int(df_train.shape[0] / train_batchsize),\n",
    "            epochs=epochs,\n",
    "            validation_data=val_generator,\n",
    "            #validation_steps=int(df_val.shape[0] / train_batchsize),\n",
    "            callbacks=callbacks_list                              \n",
    "            )\n",
    "            \n",
    "        mlflow.log_param(\"model_params\", model.count_params())\n",
    "\n",
    "                \n",
    "        for i_test, df_t in enumerate(test_cases):\n",
    "                \n",
    "            test_generator = sequence_img_generator.DataGeneratorGHI_SCNN(df_t, IMAGE_PATH, **params3)\n",
    "\n",
    "            # Test ghi\n",
    "            y_test = model.predict(test_generator) * df_t.Target_GHICS.values.reshape(-1, 1)\n",
    "            y_true = df_t.Target_GHIr.values\n",
    "            y_pers = df_t.ghi1.values\n",
    "                    \n",
    "                    \n",
    "            mae_test = metrics.mean_squared_error(y_true, y_test)\n",
    "            mae_per = metrics.mean_squared_error(y_true, y_pers)\n",
    "                    \n",
    "            FS = 1 - mae_test / mae_per\n",
    "                \n",
    "            print(f'Test case: {df_t.date.dt.date.iloc[0]}')    \n",
    "            print(f\"model_params: {model.count_params()}\")\n",
    "            print(f\"mae_test: {mae_test}\")\n",
    "            print(f\"mae_pers {mae_per}\")\n",
    "            print(f\"FS: {FS}\")\n",
    "                \n",
    "            mlflow.log_metric(f'mae_test_{i_test}', mae_test)\n",
    "            mlflow.log_metric(f\"mae_pers_{i_test}\", mae_per)\n",
    "            mlflow.log_metric(f\"FS_{i_test}\", FS)\n",
    "                \n",
    "                \n",
    "        mlflow.tensorflow.log_model(model, f'{m}_{LEARNING_RATE_START}_{LOSS}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "A2A",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7dcf80bfe24a4c1c599ee178e16a27a6ca789ca5e1840aa335d10d61a7af269"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
